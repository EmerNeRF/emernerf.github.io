"use strict";(self.webpackChunkemernerf=self.webpackChunkemernerf||[]).push([[638],{1478:function(e,t,n){n.r(t),n.d(t,{Head:function(){return X}});var a=n(7294),l=n(9583),i=n(8193),s=n(1451),o=n(6529),r=n(1547),m=n(7933),c=n(5509),d=n(5237),u=n(3294),p=n(4322),f=n(9198),g=n(8049),E=n(6237),v=n(5665),h=n(5187),x=n(2164),b=n(3374),y=n(2673),N=n(7458),w=n(866),S=n(3051),R=n(8456),k=n(73),F=n(6491),Z=n(5523),D=n(3634),C=n(2448),T=n(4652),I=n(6249),_=n(4665),j=n(3365),B=n(6998),z=n(2728),P=n(8255),A=n(5091),W=n(5693),O=n(2589),L=n(9561),V=n(5413),H=n(6680);let q;"undefined"!=typeof window&&(q=n(8660).Z);const M=e=>{let{children:t}=e;return a.createElement("h1",{className:"pb-1 mb-6 sm:mb-5 sm:leading-tight md:leading-tight lg:leading-tight font-bold text-center"},t)},G=e=>{let{children:t}=e;return a.createElement("div",null,a.createElement("div",{className:"flex justify-center content-center"},a.createElement("p",{className:"font-semibold text-2xl sm:text-3xl m-1 sm:m-2"},"Abstract")),a.createElement("div",{className:"flex justify-center content-center"},a.createElement("p",{className:"text-justify font-light text-base sm:text-lg m-1 sm:m-1 max-w-[100%] sm:max-w-[620px]"},t)))},U=e=>{let{children:t,website:n,firstAuthor:l,affiliations:i,lastAuthor:s}=e;return a.createElement("span",{className:"text-center inline-block"},a.createElement("a",{href:n,target:"_blank",className:"font-normal no-underline text-stone-600 hover:underline underline-offset-3 hover:transition-all"},t),l||i?a.createElement("sup",{className:"pl-0.5"},l?a.createElement("span",{className:"font-bold"},"*"):null,i||null):null,s?null:a.createElement(a.Fragment,null,", "))},J=e=>{let{children:t,url:n,icon:l}=e;return a.createElement("span",{className:"text-center inline-block my-3.5 sm:my-2 mx-2"},a.createElement("a",{href:n,target:n.startsWith("#")?"_self":"_blank",className:"text-xl no-underline font-normal text-[#009cff] bg-[#f9f9f9] hover:bg-[#f4f4f4] hover:transition-all px-4 py-3 rounded-xl"},a.createElement("span",{className:"align-middle inline-flex justify-center mr-0.25"},l," "),a.createElement("span",null,t)))},K=e=>{let{children:t}=e;return a.createElement("div",{className:"mx-auto w-full max-w-[90%] format format-md md:format-base lg:max-w-5xl lg:format-lg format-blue dark:format-invert"},t)},Q=e=>{let{children:t}=e;return a.createElement("main",{className:"pt-6 lg:pt-12 bg-white dark:bg-gray-900"},t)},X=()=>a.createElement("title",null,"EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision"),Y={desktop:{breakpoint:{max:3e3,min:1024},items:3},tablet:{breakpoint:{max:1024,min:464},items:2},mobile:{breakpoint:{max:464,min:0},items:1}},$={desktop:{breakpoint:{max:3e3,min:1024},items:1},tablet:{breakpoint:{max:1024,min:464},items:1},mobile:{breakpoint:{max:464,min:0},items:1}},ee={desktop:{breakpoint:{max:3e3,min:1024},items:2},tablet:{breakpoint:{max:1024,min:464},items:2},mobile:{breakpoint:{max:464,min:0},items:1}},te=e=>{let{children:t,video:n}=e;const{0:l,1:i}=(0,a.useState)(!1),s=(0,a.useRef)(null);return(0,a.useEffect)((()=>{const e=new IntersectionObserver((e=>{e.forEach((e=>{i(e.isIntersecting)}))}));return e.observe(s.current),()=>e.disconnect()}),[]),a.createElement("div",null,a.createElement("video",{ref:s,controls:!0,autoPlay:l,muted:!0,playsInline:!0,loop:!0,alt:n,className:"carousel-video px-1.5 rounded-xl"},l&&a.createElement("source",{src:n,type:"video/mp4"})),a.createElement("p",{className:"text-center"},t))},ne=e=>{let{children:t,id:n,video:l,plotData:i,hidden:s}=e;const{0:o,1:r}=(0,a.useState)(!1),m=(0,a.useRef)(null);return(0,a.useEffect)((()=>{const e=new IntersectionObserver((e=>{e.forEach((e=>{r(e.isIntersecting)}))}));return e.observe(m.current),()=>e.disconnect()}),[]),a.createElement("div",{id:n,className:"demo-component"+(s?" hidden":"")},a.createElement("video",{ref:m,autoPlay:!0,muted:!0,playsInline:!0,loop:!0,alt:t,style:{width:"100%",display:"block",maxWidth:"none",marginBottom:0},className:"rounded-lg border border-gray-300"},a.createElement("source",{src:l,type:"video/mp4"})),o&&a.createElement(q,{data:i.data,layout:i.layout,style:{marginTop:0,display:"block",maxWidth:"100%",width:"1100px"},className:"rounded-lg"}),a.createElement("div",{className:"text-left mt-2 text-base text-gray-600"},a.createElement("sup",null,"*"),"Interact with the plot using the mouse. To optimize page load times, results are displayed every second, showcasing a sampled 1/6 of the points per frame."))},ae=e=>{let{children:t,id:n,video:l,plotData:i,hidden:s}=e;const{0:o,1:r}=(0,a.useState)(!1),m=(0,a.useRef)(null);return(0,a.useEffect)((()=>{const e=new IntersectionObserver((e=>{e.forEach((e=>{r(e.isIntersecting)}))}));return e.observe(m.current),()=>e.disconnect()}),[]),a.createElement("div",{id:n,className:"demo-component"+(s?" hidden":"")},a.createElement("video",{ref:m,autoPlay:!0,muted:!0,playsInline:!0,loop:!0,alt:t,style:{width:"100%",display:"block",maxWidth:"none",marginBottom:0},className:"rounded-lg border border-gray-300"},a.createElement("source",{src:l,type:"video/mp4"})),o&&a.createElement(q,{data:i.data,layout:i.layout,style:{marginTop:0,display:"block",maxWidth:"100%",width:"1100px"},className:"rounded-lg"}),a.createElement("div",{className:"text-left mt-2 text-base text-gray-600"},a.createElement("sup",null,"*"),"Interact with the plot using the mouse. To optimize page load times, results are displayed every second. Note: 2D and 3D features are visualized distinctly and may have different color representations. Voxel size is 0.15m."))};t.default=()=>a.createElement(a.Fragment,null,a.createElement(Q,null,a.createElement(K,null,a.createElement(M,null,a.createElement("span",{className:"font-extrabold text-transparent bg-clip-text bg-gradient-to-r from-pink-500 via-indigo-600 to-emerald-400"},"EmerNeRF:")," ",a.createElement("span",{className:"text-stone-800"},"Emergent Spatial-Temporal Scene Decomposition via Self-Supervision")),a.createElement("div",{className:"flex flex-wrap justify-center text-xl lg:text-xl mb-4"},a.createElement(U,{lastAuthor:!0},"Anonymous ")),a.createElement("p",{className:"flex flex-wrap justify-center"},a.createElement(J,{url:"https://anonymous.4open.science/r/EmerNeRF_review-003B/README.md",icon:a.createElement(i.RrF,null)},"Code"))),a.createElement("div",{className:"my-6 pt-6 pb-4 bg-gradient-to-r from-pink-100/70 via-indigo-100/70 to-emerald-100/70"},a.createElement("div",{className:"mx-auto w-full max-w-[97.5%] lg:max-w-7xl py-2 md:py-4 px-2 md:px-4"},a.createElement("div",{className:"relative pb-8 mb-3"},a.createElement("div",{className:"text-left mt-2 text-base text-gray-600"},a.createElement("sup",null,"*"),"Initial loading of videos may require a few minutes (1 to 4 minutes)."),a.createElement(o.default,{responsive:Y,infinite:!0,showDots:!0,renderDotsOutside:!0,beforeChange:(e,t)=>{let{currentSlide:n,onMove:a}=t;const l=document.getElementsByClassName("carousel-video");for(let i=0;i<l.length;i++)l[i].paused&&(l[i].play(),console.log("Started playing video "+l[i].src))}},a.createElement(te,{video:r.Z},'"Ego-static, scene_023"'),a.createElement(te,{video:u.Z},'"Gloomy, scene_047"'),a.createElement(te,{video:E.Z},'"Dusk/Dawn, scene_696"'),a.createElement(te,{video:g.Z},'"High-speed, scene_02"'),a.createElement(te,{video:m.Z},'"Ego-static, scene_114"'),a.createElement(te,{video:d.Z},'"Nighttime, scene_015"'),a.createElement(te,{video:p.Z},'"Gloomy, scene_284"'),a.createElement(te,{video:f.Z},'"Rainy, scene_244"'),a.createElement(te,{video:c.Z},'"Ego-static, scene_115"'))),a.createElement("p",{className:"text-center text-lg md:text-xl md:max-w-[85%] mx-auto"},"Using only self-supervision, EmerNeRF effectively decomposes dynamic scenes into static and dynamic components.",a.createElement("br",null),"Importantly, EmerNeRF derives scene flows without explicit flow supervision."))),a.createElement(K,null,a.createElement(G,null,"We present EmerNeRF, a simple yet powerful approach for learning spatial-temporal representations of dynamic driving scenes. Grounded in neural fields, EmerNeRF simultaneously captures scene geometry, appearance, motion, and semantics via self-bootstrapping. EmerNeRF hinges upon two core components: First, it stratifies scenes into static and dynamic fields. This decomposition emerges purely from self-supervision, enabling our model to learn from general, in-the-wild data sources. Second, EmerNeRF parameterizes an induced flow field from the dynamic field and uses this flow field to further aggregate multi-frame features, amplifying the rendering precision of dynamic objects. Coupling these three fields (static, dynamic, and flow) enables EmerNeRF to represent highly-dynamic scenes self-sufficiently, without relying on ground truth object annotations or pre-trained models for dynamic object segmentation or optical flow estimation. Our method achieves state-of-the-art performance in sensor simulation, significantly outperforming previous methods when reconstructing static (+2.39 PSNR) and dynamic (+3.25 PSNR) scenes. In addition, to bolster EmerNeRF's semantic generalization, we lift 2D visual foundation model features into 4D space-time and address a general positional bias in modern Transformers, significantly boosting 3D perception performance (e.g., 78.5% relative improvement in occupancy prediction accuracy). Finally, we construct a diverse and challenging 120-sequence dataset to benchmark neural fields under extreme and highly-dynamic settings."),a.createElement("h2",{className:"font-semibold border-b-[1px] !mb-4"},"Exploring the Potential of EmerNeRF representations"),a.createElement("h3",{className:"!mt-4",id:"flow-estimation"},"Self-supervised Scene Flow Estimation"),a.createElement("p",null,"EmerNeRF demonstrates emerging flow estimation properties without explicit flow supervision. EmerNeRF's approach to flow estimation does not rely on explicit flow supervision. Instead, its effectiveness is derived from optimizing scene reconstruction losses and temporal aggregation. Through the integration of temporally-consistent features across multiple frames, it achieves accurate scene flow predictions."),a.createElement("div",{className:"my-4 leading-8"},a.createElement("span",{className:"text-xl mr-1"},"Show results for "),a.createElement("select",{className:"rounded-xl",onChange:e=>{const t=e.target.value,n=document.getElementById(t);if(null===n)return void console.log("div "+t+" is null! ");const a=document.getElementsByClassName("demo-component");for(let l=0;l<a.length;l++)a[l]===n||a[l].classList.contains("hidden")||(a[l].classList.add("hidden"),a[l].getElementsByTagName("video")[0].currentTime=0,console.log("Hiding div "+a[l].id+" and reset video"));n.classList.remove("hidden"),console.log("Showing div "+n.id)}},a.createElement("option",{value:"scene_700"},"scene 700"),a.createElement("option",{value:"scene_754"},"scene 754"))),a.createElement(ne,{id:"scene_700",video:v.Z,plotData:h}),a.createElement(ne,{id:"scene_754",video:x.Z,plotData:b,hidden:!0}),a.createElement("div",{className:"pt-6 border-b-[1px] !mb-6"}),a.createElement("h3",{id:"novel-view-synthesis",className:"!mt-4"},"Novel View Synthesis"),a.createElement("p",null,"EmerNeRF effectively reconstructs spatial-temporal scenes, generating high-quality views of both static and dynamic elements. For demonstration, a novel trajectory is rendered by:"),a.createElement("ol",null,a.createElement("li",null,"Following the camera's initial video path.."),a.createElement("li",null,"Synthesize novel views while pausing time."),a.createElement("li",null,"Returning to the camera's initial path."),a.createElement("li",null,"Fixing the ego-center and allowing time progression.")),"However, it's worth noting that once the ego-center is set in place (step 4), subsequent synthesized views may exhibit increased noise due to the absence of further observations in training data.",a.createElement("div",{className:"mx-auto w-full max-w-[97.5%] lg:max-w-7xl py-2 md:py-4 px-2 md:px-4"},a.createElement("div",{className:"relative pb-8 mb-3"},a.createElement(o.default,{responsive:ee,infinite:!0,showDots:!0,renderDotsOutside:!0,beforeChange:(e,t)=>{let{currentSlide:n,onMove:a}=t;const l=document.getElementsByClassName("carousel-video");for(let i=0;i<l.length;i++)l[i].paused&&(l[i].play(),console.log("Started playing video "+l[i].src))}},a.createElement(te,{video:j.Z}),a.createElement(te,{video:D.Z}),a.createElement(te,{video:B.Z}),a.createElement(te,{video:C.Z}),a.createElement(te,{video:T.Z}),a.createElement(te,{video:I.Z}),a.createElement(te,{video:_.Z}))),a.createElement("p",{className:"text-center text-lg md:text-xl md:max-w-[85%] mx-auto"},a.createElement("b",null,"EmerNeRF synthesizes high-quality novel appearances, depth and object motions."))),a.createElement("div",{className:"pt-6 border-b-[1px] !mb-6"}),a.createElement("h3",{id:"feature-decomposed",className:"!mt-4"},"Positional Embedding Decomposition"),a.createElement("p",null,"We observe prominent and undesired PE patterns when using current state-of-the-art foundation models, notably DINOv2. These patterns persist across images regardless of 3D viewpoint shifts, violating 3D multi-view consistency. EmerNeRF offers a solution to this problem."),a.createElement("div",{className:"mx-auto w-full max-w-[97.5%] lg:max-w-7xl py-2 md:py-4 px-2 md:px-4"},a.createElement("div",{className:"relative pb-8 mb-3"},a.createElement(o.default,{responsive:$,infinite:!0,showDots:!0,renderDotsOutside:!0,beforeChange:(e,t)=>{let{currentSlide:n,onMove:a}=t;const l=document.getElementsByClassName("carousel-video");for(let i=0;i<l.length;i++)l[i].paused&&(l[i].play(),console.log("Started playing video "+l[i].src))}},a.createElement(te,{video:w.Z}),a.createElement(te,{video:S.Z}),a.createElement(te,{video:R.Z}),a.createElement(te,{video:k.Z}),a.createElement(te,{video:F.Z}),a.createElement(te,{video:Z.Z}))),a.createElement("p",{className:"text-center text-lg md:text-xl md:max-w-[85%] mx-auto"},a.createElement("b",null,"EmerNeRF frees foundation models from positional embedding artifacts."))),a.createElement("p",null,"Without the introduced PE decomposition, NeRF exhibits noticeable PE artifacts, leading to foggy floaters and ghosting in the rendered features."),a.createElement("div",{className:"mx-auto w-full max-w-[97.5%] lg:max-w-7xl py-2 md:py-4 px-2 md:px-4"},a.createElement("div",{className:"relative pb-8 mb-3"},a.createElement(o.default,{responsive:ee,infinite:!0,showDots:!0,renderDotsOutside:!0,beforeChange:(e,t)=>{let{currentSlide:n,onMove:a}=t;const l=document.getElementsByClassName("carousel-video");for(let i=0;i<l.length;i++)l[i].paused&&(l[i].play(),console.log("Started playing video "+l[i].src))}},a.createElement(te,{video:O.Z},"Scene Reconstruction"),a.createElement(te,{video:L.Z},"Novel View Synthesis"),a.createElement(te,{video:V.Z},"Scene Reconstruction"),a.createElement(te,{video:H.Z},"Novel View Synthesis"),a.createElement(te,{video:z.Z},"Scene Reconstruction"),a.createElement(te,{video:P.Z},"Novel View Synthesis"),a.createElement(te,{video:A.Z},"Scene Reconstruction"),a.createElement(te,{video:W.Z},"Novel View Synthesis"))),a.createElement("p",{className:"text-center text-lg md:text-xl md:max-w-[85%] mx-auto"},a.createElement("b",null,"Comparison of EmerNeRF with and without our proposed positional embedding decomposition.")," PCA has randomness, so the colors may vary across scene reconstructions and novel view synthesis.")),a.createElement("div",{className:"pt-6 border-b-[1px] !mb-6"}),a.createElement("h3",{className:"!mt-4",id:"flow-estimation"},"Spatial-Temporal Foundation Feature Fields"),a.createElement("p",null,"EmerNeRF leverages the robust semantics of 2D vision foundation models, overcoming their positional embedding limitations. We visualize the lifted spatial-temporal features."),a.createElement("div",{className:"my-4 leading-8"},a.createElement("span",{className:"text-xl mr-1"},"Show results for "),a.createElement("select",{className:"rounded-xl",onChange:e=>{const t=e.target.value,n=document.getElementById(t);if(null===n)return void console.log("div "+t+" is null! ");const a=document.getElementsByClassName("demo-component");for(let l=0;l<a.length;l++)a[l]===n||a[l].classList.contains("hidden")||(a[l].classList.add("hidden"),a[l].getElementsByTagName("video")[0].currentTime=0,console.log("Hiding div "+a[l].id+" and reset video"));n.classList.remove("hidden"),console.log("Showing div "+n.id)}},a.createElement("option",{value:"feature_754"},"scene 754"))),a.createElement(ae,{id:"feature_754",video:y.Z,plotData:N}),a.createElement("h2",{id:"citation",className:"border-b-[1px]"},"Citation"),a.createElement("div",{className:"relative overflow-auto"},a.createElement("pre",{className:"bg-gradient-to-r from-pink-100 via-indigo-100 to-emerald-100 !my-0"},a.createElement("code",{id:"citation-bib",className:"font-medium text-slate-800"},"@inproceedings{emernerf,\ntitle={EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision},\nauthor={Anonymous Authors},\nbooktitle={The Twelveth International Conference on Learning Representations},\nyear={2024}\n}")),a.createElement("div",{className:"absolute top-0 right-0"},a.createElement("button",{className:"float-right text-2xl text-indigo-500 bg-white hover:bg-slate-50 hover:text-indigo-600 hover:transition-all rounded-full p-2 m-3 invisible md:visible",onClick:()=>{let e=document.getElementById("citation-bib"),t=document.createRange(),n=window.getSelection();null!=e&&null!=t&&null!=n&&(t.selectNode(e),n.removeAllRanges(),n.addRange(t))}},a.createElement(s.DV2,null))))),a.createElement("footer",{className:"flex flex-col justify-center bg-gray-50 mt-8 py-8"},a.createElement("div",{className:"flex justify-center align-middle text-lg"},a.createElement("a",{role:"button",className:"text-blue-500",onClick:()=>{window.scrollTo({top:0,behavior:"smooth"})}},a.createElement("span",{className:"align-text-top inline-flex justify-center mr-0.25"},a.createElement(l.ZTc,null)," "),a.createElement("span",null,"Back to Top"))),a.createElement("div",{className:"mt-2.5 text-center"},"Website borrowed from  ",a.createElement("a",{href:"https://github.com/f3rm/f3rm.github.io",target:"_blank",className:"text-blue-500"},a.createElement("span",{className:"align-text-top inline-flex justify-center mr-0.25"},a.createElement(i.RrF,null)," "),a.createElement("span",null,"GitHub"))))))}}]);
//# sourceMappingURL=component---src-pages-index-bk-tsx-87e2d9039a069eccc23e.js.map